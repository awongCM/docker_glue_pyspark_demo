name: Run Tests with LocalStack

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      localstack:
        image: localstack/localstack:latest
        env:
          SERVICES: dynamodb,s3,cloudwatch,logs,iam,sts
          DEFAULT_REGION: us-east-1
          AWS_ACCESS_KEY_ID: test
          AWS_SECRET_ACCESS_KEY: test
          DEBUG: 1
        ports:
          - 4566:4566
        options: >-
          --health-cmd "awslocal s3 ls || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build Glue PySpark Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: false
          load: true
          tags: my-glue-pyspark:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Wait for LocalStack to be ready
        run: |
          echo "Waiting for LocalStack to be ready..."
          max_attempts=30
          attempt=0
          until curl -s http://localhost:4566/_localstack/health | grep -q '"s3": "available"' || [ $attempt -eq $max_attempts ]; do
            echo "Attempt $((++attempt))/$max_attempts: Waiting for LocalStack..."
            sleep 2
          done
          if [ $attempt -eq $max_attempts ]; then
            echo "LocalStack failed to start"
            exit 1
          fi
          echo "LocalStack is ready!"

      - name: Configure AWS resources in LocalStack
        run: |
          docker run --rm \
            --network host \
            -e AWS_ACCESS_KEY_ID=test \
            -e AWS_SECRET_ACCESS_KEY=test \
            -e AWS_REGION=us-east-1 \
            amazon/aws-cli:latest \
            --endpoint-url=http://localhost:4566 s3 mb s3://bronze-bucket || true

          docker run --rm \
            --network host \
            -e AWS_ACCESS_KEY_ID=test \
            -e AWS_SECRET_ACCESS_KEY=test \
            -e AWS_REGION=us-east-1 \
            amazon/aws-cli:latest \
            --endpoint-url=http://localhost:4566 s3 mb s3://iceberg || true

          docker run --rm \
            --network host \
            -e AWS_ACCESS_KEY_ID=test \
            -e AWS_SECRET_ACCESS_KEY=test \
            -e AWS_REGION=us-east-1 \
            amazon/aws-cli:latest \
            --endpoint-url=http://localhost:4566 dynamodb create-table \
            --table-name gold_table_plain \
            --attribute-definitions AttributeName=id,AttributeType=N \
            --key-schema AttributeName=id,KeyType=HASH \
            --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 || true

          docker run --rm \
            --network host \
            -e AWS_ACCESS_KEY_ID=test \
            -e AWS_SECRET_ACCESS_KEY=test \
            -e AWS_REGION=us-east-1 \
            amazon/aws-cli:latest \
            --endpoint-url=http://localhost:4566 dynamodb create-table \
            --table-name gold_table_po \
            --attribute-definitions AttributeName=id,AttributeType=N \
            --key-schema AttributeName=id,KeyType=HASH \
            --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 || true

          docker run --rm \
            --network host \
            -e AWS_ACCESS_KEY_ID=test \
            -e AWS_SECRET_ACCESS_KEY=test \
            -e AWS_REGION=us-east-1 \
            amazon/aws-cli:latest \
            --endpoint-url=http://localhost:4566 logs create-log-group \
            --log-group-name /aws/glue/jobs/pyspark-logs || true

          docker run --rm \
            --network host \
            -e AWS_ACCESS_KEY_ID=test \
            -e AWS_SECRET_ACCESS_KEY=test \
            -e AWS_REGION=us-east-1 \
            amazon/aws-cli:latest \
            --endpoint-url=http://localhost:4566 logs create-log-stream \
            --log-group-name /aws/glue/jobs/pyspark-logs \
            --log-stream-name plain-bronze || true

      - name: Run tests inside Glue container
        run: |
          docker run --rm \
            --network host \
            -v ${{ github.workspace }}/plain:/app/plain \
            -v ${{ github.workspace }}/purchase_order:/app/purchase_order \
            -v ${{ github.workspace }}/tests:/app/tests \
            -v ${{ github.workspace }}/pytest.ini:/app/pytest.ini \
            -e AWS_ACCESS_KEY_ID=test \
            -e AWS_SECRET_ACCESS_KEY=test \
            -e AWS_REGION=us-east-1 \
            my-glue-pyspark:latest \
            "poetry run pytest tests/ --cov=plain --cov=purchase_order --cov-report=term-missing --cov-report=xml --cov-report=html -v"

      - name: Copy coverage reports from container
        if: always()
        run: |
          # Coverage files are generated inside the container's /app directory
          # They should already be in the workspace due to volume mounts
          ls -la coverage.xml htmlcov/ || echo "Coverage files not found"

      - name: Upload coverage reports
        uses: codecov/codecov-action@v4
        if: always()
        with:
          files: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Upload coverage HTML report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-report
          path: htmlcov/
          retention-days: 7
